# ============================================================================
# FLUENT BIT - VALUES.YAML COMPLET ȘI DETALIAT
# ============================================================================
# Configurație pentru colectare logs Kubernetes → Fluentd
# Documentație: https://docs.fluentbit.io/manual/
# ============================================================================

# ----------------------------------------------------------------------------
# IMAGE CONFIGURATION
# ----------------------------------------------------------------------------
image:
  repository: fluent/fluent-bit
  pullPolicy: IfNotPresent # IfNotPresent = trage doar dacă nu există | Always = trage mereu
  tag: "0.54.0" # Verifică versiuni: https://github.com/fluent/fluent-bit/releases

imagePullSecrets: [] # Folosește dacă ai registry privat: [{ name: my-registry-secret }]

# ----------------------------------------------------------------------------
# SERVICE ACCOUNT & RBAC
# ----------------------------------------------------------------------------
serviceAccount:
  create: true # Creează ServiceAccount automat
  annotations: {} # Exemplu AWS IRSA: eks.amazonaws.com/role-arn: arn:aws:iam::...
  name: fluent-bit

rbac:
  create: true # NECESAR pentru Kubernetes metadata enrichment
  nodeAccess: true # Permite citirea informațiilor despre noduri

# ----------------------------------------------------------------------------
# POD CONFIGURATION
# ----------------------------------------------------------------------------
podAnnotations:
  # Prometheus scraping - permite colectarea de metrici
  prometheus.io/scrape: "true"
  prometheus.io/port: "2020"
  prometheus.io/path: "/api/v1/metrics/prometheus"

podLabels:
  app.kubernetes.io/name: fluent-bit
  app.kubernetes.io/component: log-collector

# Security Context - Fluent Bit TREBUIE să ruleze ca root pentru a citi /var/log
podSecurityContext:
  runAsNonRoot: false
  runAsUser: 0
  fsGroup: 0

securityContext:
  capabilities:
    drop: [ALL]
    add:
      - DAC_READ_SEARCH # Citește fișiere fără verificare permisiuni
      - SYS_ADMIN # Acces la hostPath volumes
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false

# ----------------------------------------------------------------------------
# DAEMONSET - Rulează pe TOATE nodurile
# ----------------------------------------------------------------------------
kind: DaemonSet

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1 # Update un nod odată (safe)

priorityClassName: system-node-critical # Prioritate maximă, nu e evicted

# ----------------------------------------------------------------------------
# RESOURCES - Ajustează în funcție de volumul de logs
# ----------------------------------------------------------------------------
# Ghid:
#   Cluster mic (<20 noduri): 100m CPU, 128Mi RAM
#   Cluster mediu (20-100 noduri): 200m CPU, 256Mi RAM
#   Cluster mare (>100 noduri): 500m CPU, 512Mi RAM
resources:
  limits:
    cpu: 500m # Maxim CPU - crește dacă vezi throttling
    memory: 512Mi # Maxim RAM - crește dacă vezi OOMKilled
  requests:
    cpu: 100m # CPU rezervat - 20-30% din limit
    memory: 128Mi # RAM rezervat - 50% din limit

# ----------------------------------------------------------------------------
# NODE SELECTION & TOLERATIONS
# ----------------------------------------------------------------------------
nodeSelector: {} # Rulează pe toate nodurile - adaugă doar dacă vrei restricții specifice

# Tolerations - permite rularea pe noduri cu taints (inclusiv master)
tolerations:
  - key: "node-role.kubernetes.io/master"
    operator: "Exists"
    effect: "NoSchedule"
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Exists"
    effect: "NoSchedule"
  - operator: "Exists" # Tolerează orice taint
    effect: "NoExecute"
  - operator: "Exists"
    effect: "NoSchedule"

affinity: {}

# ----------------------------------------------------------------------------
# VOLUMES - Acces la logs și metadata Kubernetes
# ----------------------------------------------------------------------------
volumeMounts:
  - name: varlog
    mountPath: /var/log
    readOnly: true
  - name: varlibdockercontainers
    mountPath: /var/lib/containerd # Sau /var/lib/containerd pentru containerd
    readOnly: true
  - name: etcmachineid
    mountPath: /etc/machine-id
    readOnly: true
  - name: systemd
    mountPath: /run/systemd
    readOnly: true
  - name: fluent-bit-buffer
    mountPath: /fluent-bit/buffer

daemonSetVolumes:
  - name: varlog
    hostPath:
      path: /var/log
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containerd # SCHIMBĂ cu /var/lib/containerd dacă folosești containerd
  - name: etcmachineid
    hostPath:
      path: /etc/machine-id
      type: FileOrCreate
  - name: systemd
    hostPath:
      path: /run/systemd
  - name: fluent-bit-buffer
    emptyDir: {}

extraVolumes: []
extraVolumeMounts: []

# ----------------------------------------------------------------------------
# SERVICE - Expune HTTP server pentru metrics
# ----------------------------------------------------------------------------
service:
  type: ClusterIP
  port: 2020
  labels: {}
  annotations: {}

serviceMonitor:
  enabled: false # Set true dacă folosești Prometheus Operator

# ----------------------------------------------------------------------------
# HEALTH CHECKS
# ----------------------------------------------------------------------------
livenessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /api/v1/health
    port: http
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# ----------------------------------------------------------------------------
# ENVIRONMENT VARIABLES
# ----------------------------------------------------------------------------
env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: POD_NAME
    valueFrom:
      fieldRef:
        fieldPath: metadata.name
  - name: POD_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
  - name: CLUSTER_NAME
    value: "microk8s-cluster"

# ============================================================================
# FLUENT BIT CONFIGURATION
# ============================================================================
config:
  # --------------------------------------------------------------------------
  # FLUENT BIT - CONFIGURAȚIE (SERVICE / INPUT / FILTER / OUTPUT / PARSERS)
  # Adaptată pentru: MicroK8s cu containerd, cluster mic (2 noduri, unul master)
  # --------------------------------------------------------------------------
  |
  ###########################################################################
  # [SERVICE] - Configurație globală Fluent Bit
  #
  # Scop: setează comportamentul global (flush, logging, HTTP server, storage).
  # De ce aceste valori pentru infra ta:
  #  - Flush 5s: bun echilibru pentru latență vs eficiență într-un cluster mic.
  #  - Daemon Off: kubelet gestionează lifecycle (folosești DaemonSet).
  #  - HTTP_Server On: utile pentru health checks & metrics (port 2020).
  #  - storage.path: folosește un path montat în pod (/fluent-bit/buffer).
  #    IMPORTANT: dacă folosești emptyDir pentru buffer -> datele se pierd la restart.
  #    Dacă vrei persistenta (recomandat doar dacă Fluentd/collector nu e garantat HA),
  #    montează un hostPath sau PVC către acest path (vezi valori volumes).
  ###########################################################################
  service: |
    [SERVICE]
      Flush                     5
      Daemon                    Off
      Log_Level                 info
      Parsers_File              parsers.conf
      Parsers_File              custom_parsers.conf

      # HTTP server - metrics / health (utile pentru Prometheus / debugging)
      HTTP_Server               On
      HTTP_Listen               0.0.0.0
      HTTP_Port                 2020
      # Endpoints: / , /api/v1/metrics/prometheus , /api/v1/health

      # Storage (buffer) - folosește storage local pentru când Fluentd e down
      # - storage.path: location montată în container (vezi volumeMounts: fluent-bit-buffer)
      # - storage.type (setată per INPUT) filesystem = persistă DB/offsets pe disk
      # NOTE: dacă folosești emptyDir, buffer va supraviețui doar atâta timp cât podul
      #       este pe același nod. La reschedule pe alt nod, offset-uri se pierd.
      storage.path              /fluent-bit/buffer
      storage.sync              normal
      storage.checksum          off
      storage.max_chunks_up     128
      storage.backlog.mem_limit 5M

  ###########################################################################
  # [INPUT] - Tail (citire logs container CRI / containerd)
  #
  # Adaptări pentru containerd + MicroK8s:
  #  - Path: MicroK8s (containerd) tipic: /var/log/containers/*.log
  #    (fisiere generate de kubelet + symlink-uri către /var/log/pods/...).
  #  - Parser: 'cri' pentru containerd/CRI logs (conține timestamp + stream + log).
  #  - DB: stochează poziția de citire (critical pentru a evita re-procesarea la restart).
  #  - storage.type filesystem + DB = persistă offset-urile pe disk (recomandat).
  #
  # Observații practice:
  #  - Dacă folosești containerd, asigură-te că daemonSetVolumes folosește
  #    hostPath: /var/log/pods (sau /var/log/containers) și /var/lib/containerd
  #  - Exclude_Path evită bucla dacă Fluent Bit scrie în /var/log/containers
  ###########################################################################
  inputs: |
    [INPUT]
        Name                tail

        # Path către container logs (containerd / MicroK8s)
        Path                /var/log/containers/*.log

        # Evită procesarea log-urilor Fluent Bit însuși (previne loop)
        Exclude_Path        /var/log/containers/*fluent*.log

        # Parser pentru container runtime CRI (containerd)
        # - MicroK8s folosește implicit containerd -> Parser=cri
        Parser              cri

        # Tag folosit pentru routing (folosit în filtre/outputs)
        Tag                 kube.*

        # Cât de des să scaneze pentru fișiere noi (la cluster mic, 5s e OK)
        Refresh_Interval    5

        # Buffer per file (memorie)
        Mem_Buf_Limit       5MB

        # Evită linii excesiv de lungi care pot bloca memoria
        Skip_Long_Lines     On

        # Evită linii goale
        Skip_Empty_Lines    On

        # DB persistă poziția (critical). DB path trebuie să fie pe storage.path.
        DB                  /fluent-bit/buffer/tail-containers.db
        DB.locking          true

        # Tipul de storage pentru INPUT: filesystem = persistă la crash
        storage.type        filesystem

    # OPTIONAL: systemd input - utile dacă vrei loguri de la kubelet/containerd
    # Dacă vrei să adaugi, decomentează și configurează Systemd_Filter corespunzător.
    # Exemplu (doar dacă vrei să colectezi logs host services):
    # [INPUT]
    #     Name                systemd
    #     Tag                 host.*
    #     Systemd_Filter      _SYSTEMD_UNIT=kubelet.service
    #     Systemd_Filter      _SYSTEMD_UNIT=containerd.service
    #     Read_From_Tail      On
    #     Strip_Underscores   On

    # OPTIONAL: kubernetes_events - utile pentru audit/tracking pod lifecycle
    # Dacă vrei evenimente (pod created/deleted/oom), decomentează.
    # Reține: folosește token/CA din service account montat automat în pod.
    # [INPUT]
    #     Name                kubernetes_events
    #     Tag                 kube.events
    #     Kube_URL            https://kubernetes.default.svc:443
    #     Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    #     Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
    #     Interval_Sec        60

  ###########################################################################
  # [FILTER] - Enrichment & modificări
  #
  # Scop: adaugă metadata Kubernetes (pod, namespace, labels), câmpuri custom,
  #       și face parsing suplimentar dacă aplicațiile emit JSON.
  #
  # IMPORTANT pentru MicroK8s:
  #  - Kube_URL + token/CA folosesc service account montat în pod (standard).
  #  - Use_Kubelet On: reduce apelurile către API server pentru anumite metadata,
  #    dar necesită acces la kubelet (port 10250) — pe master acest port poate fi
  #    accesibil doar local; asigură-te că ServiceAccount are permisiunile necesare.
  #  - Dacă ai un nod master cu taint, Fluent Bit rulează pe master doar dacă ai
  #    tolerations (setate în DaemonSet) — vezi secțiunea de tolerations.
  ###########################################################################
  filters: |
    [FILTER]
        Name                kubernetes
        Match               kube.*

        # Kubernetes API config - folosește secrets montate automat
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token

        # Prefixuri / mapping pentru tag-uri (corespunde cu Path + Tag de la INPUT)
        Kube_Tag_Prefix     kube.var.log.containers.

        # Comportament de merge / păstrare log
        Merge_Log           On    # combină mesajul 'log' cu metadata
        Keep_Log            On    # păstrează câmpul original 'log'

        # Parser settings for container logs (K8S logging)
        K8S-Logging.Parser  On
        K8S-Logging.Exclude On

        # Include labels & annotations -> FOARTE util pentru filtrare ulterioară
        Labels              On
        Annotations         On

        # Performanță: încearcă să folosească kubelet pentru anumite metadata
        Use_Kubelet         On
        Kubelet_Port        10250

        # Buffer pentru operațiuni de lookup
        Buffer_Size         32k

        # DNS tuning (dacă clusterul are DNS instabil)
        DNS_Retries         6
        DNS_Wait_Time       30

    # Adaugă câmpuri custom (cluster name, environment, node name)
    # Recomandare: folosește variabilă de mediu CLUSTER_NAME (mai flexibil)
    # - setează CLUSTER_NAME prin values.yaml env sau Helm values.
    [FILTER]
        Name                modify
        Match               kube.*

        # Exemplu: folosește variabilă de mediu (DEFINEȘTE în spec.env)
        # Add                 cluster_name ${CLUSTER_NAME}
        #
        # Dacă nu folosești variabilă, poți hardcoda (nu recomand pentru multi-cluster)
        Add                 cluster_name microk8s-cluster

        # Mediu (ex: production, staging) - util pentru routing/alerts
        Add                 environment production

        # Adaugă node name din env var setată în spec (vezi env section)
        Add                 node_name ${NODE_NAME}

    # OPTIONAL: parser filter - parsează JSON din câmpul 'log'
    # Dacă aplicațiile tale emit JSON, activează acest filter.
    # [FILTER]
    #     Name                parser
    #     Match               kube.*
    #     Key_Name            log
    #     Parser              json
    #     Reserve_Data        On
    #     Preserve_Key        On

    # OPTIONAL: filtre pentru exclude (grep) sau throttle (rate limiting)
    # Exemplu: exclude logs din kube-system pentru a reduce zgomotul:
    # [FILTER]
    #     Name                grep
    #     Match               kube.*
    #     Exclude             $kubernetes['namespace_name'] kube-system

  ###########################################################################
  # [OUTPUT] - Unde trimitem logs (în exemplu: FORWARD → Fluentd aggregator)
  #
  # Observații pentru setup-ul tău (2 noduri, MicroK8s):
  #  - Forward către Fluentd (daemon/deployment) în namespace 'logging' este comun.
  #  - Host: fluentd.logging.svc.cluster.local - asigură-te că serviciul Fluentd
  #    e expus și are selector corect (Service de tip ClusterIP).
  #  - Retry_Limit: retry la eșec (5 retries), dar dacă vrei retry nelimitat,
  #    configurează Fluentd să accepte și să aibă buffer persistent.
  #  - Compress gzip: reduce bandwith între Fluent Bit și Fluentd.
  ###########################################################################
  outputs: |
    [OUTPUT]
        Name                forward
        Match               kube.*

        # Schimbă cu service-ul tău Fluentd (exemplu standard în namespace logging)
        Host                fluentd.logging.svc.cluster.local
        Port                24224

        # Retry & networking
        Retry_Limit         5
        net.keepalive       on
        net.keepalive_idle_timeout 30

        # Compress pentru reducerea traficului
        Compress            gzip

        # Storage limit (local) - când Fluentd e down, Fluent Bit păstrează date locale
        # NOTĂ: aceasta controlează cât buffer local folosim pentru OUTPUT.
        storage.total_limit_size 10M

    # OPTIONAL: output direct către Loki / Elasticsearch etc.
    # Dacă vrei să trimiți direct (fără Fluentd) decomentează și configurează corespunzător.
    # Exemplu Loki:
    # [OUTPUT]
    #     Name                loki
    #     Match               kube.*
    #     Host                loki.logging.svc.cluster.local
    #     Port                3100
    #     Labels              job=fluentbit, cluster=microk8s
    #     auto_kubernetes_labels on

    # Exemplu Elasticsearch (direct):
    # [OUTPUT]
    #     Name                es
    #     Match               kube.*
    #     Host                elasticsearch.logging.svc.cluster.local
    #     Port                9200
    #     Index               kubernetes-logs
    #     Type                _doc
    #     Logstash_Format     On
    #     Retry_Limit         5

  ###########################################################################
  # [PARSERS] - Parsere custom (CRITICAL pentru containerd/CRI logs)
  #
  # - Parser 'cri' pentru containerd: acest regex captează timestamp + stream + rest
  # - Asigură Time_Format corect pentru a păstra timestamp-ul original
  ###########################################################################
extraParsers: |
  [PARSER]
      Name                cri
      Format              regex
      # Regex breakdown:
      #  - (?<time>[^ ]+) => timestamp (ex: 2025-10-12T12:34:56.123456789Z)
      #  - (?<stream>stdout|stderr) => stream
      #  - (?<logtag>[^ ]*) => optional tag (deprecated)
      #  - (?<log>.*) => restul mesajului de log
      Regex               ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
      Time_Key            time
      # Time_Format pentru nano/microseconds - %L gestionează milisecunde
      # Ajustează dacă observi diferențe (ex: %N pentru nanosec, dar nu este suportat peste tot)
      Time_Format         %Y-%m-%dT%H:%M:%S.%L%z
      Time_Keep           On

  [PARSER]
      Name                json
      Format              json
      Time_Key            time
      Time_Format         %Y-%m-%dT%H:%M:%S.%L%z
      Time_Keep           On

  [PARSER]
      Name                docker
      Format              json
      Time_Key            time
      Time_Format         %Y-%m-%dT%H:%M:%S.%L%z
      Time_Keep           On
      Decode_Field_As     escaped_utf8 log do_next
      Decode_Field_As     json log

  # Parsere pentru nginx/apache - utile dacă colectezi logs de acces
  [PARSER]
      Name                nginx
      Format              regex
      Regex               ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
      Time_Key            time
      Time_Format         %d/%b/%Y:%H:%M:%S %z

  [PARSER]
      Name                apache
      Format              regex
      Regex               ^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
      Time_Key            time
      Time_Format         %d/%b/%Y:%H:%M:%S %z

# ============================================================================
# NOTES & TROUBLESHOOTING
# ============================================================================
#
# 1. VERIFICARE DEPLOYMENT:
#    kubectl get pods -n logging -l app.kubernetes.io/name=fluent-bit
#    kubectl logs -n logging -l app.kubernetes.io/name=fluent-bit -f
#
# 2. VERIFICARE METRICS:
#    kubectl port-forward -n logging svc/fluent-bit 2020:2020
#    curl http://localhost:2020/api/v1/metrics/prometheus
#
# 3. COMMON ISSUES:
#    - OOMKilled: Crește memory limits
#    - CPU throttling: Crește CPU limits
#    - Logs delayed: Scade Flush interval sau crește resources
#    - "Permission denied": Verifică securityContext și volumes
#    - "Connection refused" la Fluentd: Verifică Host și Port în OUTPUT
#
# 4. CONTAINERD vs DOCKER:
#    - MicroK8s folosește containerd (Parser: cri)
#    - Dacă folosești Docker (Parser: docker)
#    - Path volumes: /var/lib/containerd sau /var/lib/docker/containers
#
# 5. CUSTOMIZĂRI NECESARE:
#    - Linia 232: Schimbă "my-k8s-cluster" cu numele clusterului tău
#    - Linia 328: Verifică că Fluentd service e corect: fluentd.logging.svc.cluster.local
#    - Linia 133: Verifică container runtime și ajustează path (docker vs containerd)
#
# 6. MONITORING:
#    - fluentbit_input_records_total - Records citite
#    - fluentbit_output_proc_records_total - Records trimise
#    - fluentbit_output_errors_total - Erori
#    - fluentbit_output_retries_total - Retry-uri
#
# ============================================================================
